\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}

\begin{document}
\section*{Oct 19 notes}\\
Fluency exam next week - October 27th.

\noindent \textbf{Fact 2.8.1:} Every vector space with finite dimension (every vector space V with a basis of the form $\left\{ \vec{v}_{1}, \vec{v}_{2}, \ldots, \vec{v}_{n} \right\}$) is said to be isomorphic to a Euclidean space $\mathbb{R}^{n}$ (For the purposes of this class, isomorphic just means have bases of the same size.)\\
\\
\noindent \textbf{Observation 2.8.2:} We have already seen this in action by converting polynomials and matrices into Euclidean vectors. Since $\mathcal{P}_{3}$ and $M_{2,2}$ are both four-dimensional:\\
\\
$4x^{3} + 0x^{2} - 1x + 4$ 
$\leftrightarrow$ 
$\left[\begin{matrix} 4\\0\\-1\\5 \end{matrix}\right]$ 
$\leftrightarrow$ 
$\left[\begin{matrix} 4&0\\-1&5 \end{matrix}\right]$
\\
Fact 2.4.11 If S is any subset of a vector space V , then since span S collects
all possible linear combinations, span S is automatically a subspace of V .
In fact, span S is always the smallest subspace of V that contains all the
vectors in S\\
\\
\noindent \textbf{Activity 2.8.3} \\
\\
Suppose $W$ is a subspace of $\mathcal{P}^{8}$ and you know that the set $S$ = $\left\{ x^{3} + x, x^{2} + 1, x^{4} -x  \right\}$ is a linearly independent subset of W. What can you conclude about W?\\
A. the dimension is 3 or less\\
B. the dimension of W is 3 exactly\\
C. the dimension of W is 3 or more\\
\\
- $W$ is a subspace of $\mathcal{P}^{8}$, $S$ is a sub\textbf{set} of $W$.\\
- We want to know about the dimension of $W$ and the dimension of a vector space is equal to the size of any basis for the vector space (Definition 2.7.10).\\
- We can't say anything about the basis of $W$, but we can say something about the basis of the vectors $S$ (which are a subset of $W$).\\
- Since we know the vectors of $S$ are linearly independent, we also know every column of the RREF of $S$ will have a pivot (Observation 2.5.8).\\
- The easiest basis describing a span $S$ is the set of vectors in $S$ given by the pivot columns of the RREF -- to compute a basis for a subspace, compute the RREF and remove non-pivot columns (Fact 2.7.3) \\ 
- \textbf{That means $S$ has 3 dimensions, so $W$ has at least that many (C).}\\
\\
\newpage
\noindent \textbf{Activity 2.8.3 continued} \\
Confirming the answer by computing RREF\\
$0x^{4} + x^{3} + 0x^{2} + 1x + 0$\\
$0x^{4} + 0x^{3} + x^{2} + 0x + 1$\\
$x^{4} + x^{3} + 0x^{2} - 1x + 0$\\
\\
As matrix, like exponents on same row:\\

$\left[ \begin{matrix} 
0 & 0 & 1\\
1 & 0 & 1\\
0 & 1 & 0\\
1 &0 &-1\\
0 &1& 0 \\
\end{matrix} \right]$
\begin{verbatim}
(Matrix(QQ,[
[0,0,1],
[1,0,1],
[0,1,0],
[1,0,-1],
[0,1,0]
])).rref()
[1 0 0]
[0 1 0]
[0 0 1]
[0 0 0]
[0 0 0]
\end{verbatim}\\
- Confirms that $W$ has at least 3 dimensions.\\
\\
\noindent \textbf{Activity 2.8.4} \\
Suppose $W$ is a subspace of $\mathcal{P}^{8}$ and you know that $W$ is spanned by the set\\
$S$ = $\left\{ x^{4} -x, x^{3} + x, x^{3} + x + 1, x^{4} + 2x, x^{3}, 2x + 1 \right\}$. What can you conclude about W?\\
A. the dimension is 3 or less\\
B. the dimension of W is 3 exactly\\
C. the dimension of W is 3 or more\\
\\
- We want to know about the dimension of $W$ and the dimension of a vector space is equal to the size of any basis for the vector space (Definition 2.7.10).\\
- We can't say anything about the basis of $W$, but we can say something about the basis of the vectors $S$ (which span $W$).\\
- The easiest basis describing a span $S$ is the set of vectors in $S$ given by the pivot columns of the RREF -- to compute a basis for a subspace S, compute the RREF and remove non-pivot columns (Fact 2.7.3) \\
- Since $S$ spans $W$ we have a pivot in every row of the RREF of $S$ (Observation 2.5.8).\\
- Since like-exponents go on a row, and we have 4 unique exponent-types, we should have 4 pivot rows, each with their own pivot columns.\\
- In other words, if we have a pivot on every row, we have a pivot for every term.\\
- Since we have 4 terms (no $x^{2}$ term), we have 4 pivots and 4 dimensions.\\
\\
Confirm by finding RREF:\\
\noindent As equations w zeroes filled in for clarity\\
\\
$1x^{4} + 0x^{3} + 0x^{2} - 1x + 0$\\
$0x^{4} + 1x^{3} + 0x^{2} + 1x + 0$\\
$0x^{4} + 1x^{3} + 0x^{2} + 1x + 1$\\
$1x^{4} + 0x^{3} + 0x^{2} + 2x + 0$\\
$0x^{4} + 1x^{3} + 0x^{2} + 0x + 0$\\
$0x^{4} + 0x^{3} + 0x^{2} + 2x + 1$\\
\\
As matrix, like exponents on same row:\\
$\left[ \begin{matrix} 
1 & 0 & 0 & 1 & 0 & 0\\
0 & 1 & 1 & 0 & 1 & 0\\
0 & 0 & 0 & 0 & 0 & 0\\
-1& 1 & 1 & 2 & 0 & 2\\
0 & 0 & 1 & 0 & 0 & 1 \\
\end{matrix} \right]$
\\
\begin{verbatim}
(Matrix(QQ,[
[1,0,0,1,0,0],
[0,1,1,0,1,0],
[0,0,0,0,0,0],
[-1,1,1,2,0,2],
[0,0,1,0,0,1]
])).rref()
[   1    0    0    0  1/3 -2/3]
[   0    1    0    0    1   -1]
[   0    0    1    0    0    1]
[   0    0    0    1 -1/3  2/3]
[   0    0    0    0    0    0]
\end{verbatim}\\
- Confirms that we have 4 pivot rows/columns,
- If we have a pivot on every row, we have a pivot for every term.\\
- Since we have 4 terms (no $x^{2}$ term), we have 4 pivots and 4 dimensions.\\
\\
\textbf{Observation 2.8.5:} The space of polynomials of any degree has the basis of all its exponent terms, so it is a natural example of an infinite dimensional vector space and can't be treated as an isomorphic finite-dimensional Euclidean space. \\
\\
\newpage
\noindent \textbf{Definition 2.9.1:} -- a homogeneous system of linear equations is one of form: \\
\\
$\begin{matrix} 
a_{1,1}x_{1} + a_{1,2}x_{2} + \dots + a_{1,n}x_{n} = 0\\
a_{2,1}x_{1} + a_{2,2}x_{2} + \dots + a_{2,n}x_{n} = 0\\
\vdots  \\
a_{m,1}x_{1} + a_{m,2}x_{2} + \dots + a_{m,n}x_{n} = 0\\
\end{matrix}$\\
\\
\\
Which is equivalent to the vector equation:\\
$x_{1}\vec{v}_{1} + \dots + x_{n}\vec{v}_{n}= \vec{0}$\\
\\
...And the augmented matrix:\\
\\
$\left[ \begin{matrix} 
a_{1,1} & a_{1,2} & \dots & a_{1,n} &|& 0\\
a_{2,1} & a_{2,2} & \dots & a_{2,n} &|& 0\\
\vdots & \vdots & \ddots & \vdots &|& \vdots\\
a_{m,1} & a_{m,2} & \dots & a_{m,n} &|& 0\\
\end{matrix}\right]$\\
\\
\textbf{Activity 2.9.2:} \\
Note that if 
$\left[ \begin{matrix} a_{1} \\ \vdots \\ a_{n} \end{matrix}\right]$ and 
$\left[ \begin{matrix} b_{1} \\ \vdots \\ b_{n} \end{matrix}\right]$ are solutions to $x_{1}\vec{v}_{1} + \dots + x_{n}\vec{v}_{n}= \vec{0}$,\\
\\
then so is $\left[ \begin{matrix} a_{1} + b_{1} \\ \vdots \\ a_{n} + b_{n} \end{matrix}\right]$, since $a_{1}\vec{v}_{1} + \dots + a_{n}\vec{v}_{n}= \vec{0}$ and $b_{1}\vec{v}_{1} + \dots + b_{n}\vec{v}_{n}= \vec{0}$.\\
\\
This implies that $(a{1} + b_{1})\vec{v}_{1} + \dots + (a_{n} + b_{n})\vec{v}_{n} = \vec{0}$\\
\\
Similarly, if $c \in \mathbb{R}, \left[ \begin{matrix} ca_{1}\\ \vdots \\ ca_{n} \end{matrix} \right]$ is a solution. \\
\\
Thus, the solution set of a homogenous system is:\\
\\
A. A basis for $\mathbb{R}^{n}$,\\
B. The subspace of $\mathbb{R}^{n}$,\\
or\\
C. The empty set\\
\\
Answer is B because all of the exposition in this problem just described how we are closed to vector addition and scalar multiplication, so we can say that we do have a subspace. We don't know if its linearly dependent and spans, and I'm not sure why it isn't the empty set.
\\
The first part is basically saying that if you multiply $\vec{v}_{1} \dots \vec{v}_n$ by either $\vec{a}_{1} \dots \vec{a}_n$ or $\vec{b}_{1} \dots \vec{b}_n$, you'd get a vector of zeroes ($\vec{0}$) and so they are a solution to the system.\\
\\
Since that is true, then even if we add a+b and multiply by v, it's also still a a solution (v(a+b) = 0).\\
\\
As an example, let's say our vectors are as follows:\\
\\
$ v_{1} \left[ \begin{matrix} 1 \\ 2 \end{matrix}\right]$ ,
$ v_{2} \left[ \begin{matrix} 1 \\ 0 \end{matrix}\right]$ ,
$ v_{3} \left[ \begin{matrix} 2 \\ 4 \end{matrix}\right]$ \\
\\
What values could we have for vectors $a, b, c$ where  $a\vec{v}_{1}$ + $b\vec{v}_{2}$ + $c\vec{v}_{3} = \vec{0}$ would hold true?\\
\\
$x_{1} = 0, x_{2} = 0, x_{3} = 0$\\
$x_{1} = 2, x_{2} = 0, x_{3} = -1$\\
$x_{1} = 4, x_{2} = 0, x_{3} = -2$\\
\\
And so on... such that $ \left\{ \left[ \begin{matrix} -2ac \\ 0c \\ ac \end{matrix}\right] \Biggl| a,c \in \mathbb{R} \right\}$ and $\vec{0}$ is also a solution.\\
\\
subspace is a set of vectors that's closed under vector addition and scalar multiplication\\
\\


\end{document}